{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data'][:, (2, 3)]\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1.4, 0.2],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 1.3, 0.2],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 1.7, 0.4],\n",
       "       [1. , 1.4, 0.3],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 1.5, 0.1],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.6, 0.2],\n",
       "       [1. , 1.4, 0.1],\n",
       "       [1. , 1.1, 0.1],\n",
       "       [1. , 1.2, 0.2],\n",
       "       [1. , 1.5, 0.4],\n",
       "       [1. , 1.3, 0.4],\n",
       "       [1. , 1.4, 0.3],\n",
       "       [1. , 1.7, 0.3],\n",
       "       [1. , 1.5, 0.3],\n",
       "       [1. , 1.7, 0.2],\n",
       "       [1. , 1.5, 0.4],\n",
       "       [1. , 1. , 0.2],\n",
       "       [1. , 1.7, 0.5],\n",
       "       [1. , 1.9, 0.2],\n",
       "       [1. , 1.6, 0.2],\n",
       "       [1. , 1.6, 0.4],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 1.6, 0.2],\n",
       "       [1. , 1.6, 0.2],\n",
       "       [1. , 1.5, 0.4],\n",
       "       [1. , 1.5, 0.1],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.2, 0.2],\n",
       "       [1. , 1.3, 0.2],\n",
       "       [1. , 1.4, 0.1],\n",
       "       [1. , 1.3, 0.2],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.3, 0.3],\n",
       "       [1. , 1.3, 0.3],\n",
       "       [1. , 1.3, 0.2],\n",
       "       [1. , 1.6, 0.6],\n",
       "       [1. , 1.9, 0.4],\n",
       "       [1. , 1.4, 0.3],\n",
       "       [1. , 1.6, 0.2],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 1.5, 0.2],\n",
       "       [1. , 1.4, 0.2],\n",
       "       [1. , 4.7, 1.4],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 4.9, 1.5],\n",
       "       [1. , 4. , 1.3],\n",
       "       [1. , 4.6, 1.5],\n",
       "       [1. , 4.5, 1.3],\n",
       "       [1. , 4.7, 1.6],\n",
       "       [1. , 3.3, 1. ],\n",
       "       [1. , 4.6, 1.3],\n",
       "       [1. , 3.9, 1.4],\n",
       "       [1. , 3.5, 1. ],\n",
       "       [1. , 4.2, 1.5],\n",
       "       [1. , 4. , 1. ],\n",
       "       [1. , 4.7, 1.4],\n",
       "       [1. , 3.6, 1.3],\n",
       "       [1. , 4.4, 1.4],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 4.1, 1. ],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 3.9, 1.1],\n",
       "       [1. , 4.8, 1.8],\n",
       "       [1. , 4. , 1.3],\n",
       "       [1. , 4.9, 1.5],\n",
       "       [1. , 4.7, 1.2],\n",
       "       [1. , 4.3, 1.3],\n",
       "       [1. , 4.4, 1.4],\n",
       "       [1. , 4.8, 1.4],\n",
       "       [1. , 5. , 1.7],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 3.5, 1. ],\n",
       "       [1. , 3.8, 1.1],\n",
       "       [1. , 3.7, 1. ],\n",
       "       [1. , 3.9, 1.2],\n",
       "       [1. , 5.1, 1.6],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 4.5, 1.6],\n",
       "       [1. , 4.7, 1.5],\n",
       "       [1. , 4.4, 1.3],\n",
       "       [1. , 4.1, 1.3],\n",
       "       [1. , 4. , 1.3],\n",
       "       [1. , 4.4, 1.2],\n",
       "       [1. , 4.6, 1.4],\n",
       "       [1. , 4. , 1.2],\n",
       "       [1. , 3.3, 1. ],\n",
       "       [1. , 4.2, 1.3],\n",
       "       [1. , 4.2, 1.2],\n",
       "       [1. , 4.2, 1.3],\n",
       "       [1. , 4.3, 1.3],\n",
       "       [1. , 3. , 1.1],\n",
       "       [1. , 4.1, 1.3],\n",
       "       [1. , 6. , 2.5],\n",
       "       [1. , 5.1, 1.9],\n",
       "       [1. , 5.9, 2.1],\n",
       "       [1. , 5.6, 1.8],\n",
       "       [1. , 5.8, 2.2],\n",
       "       [1. , 6.6, 2.1],\n",
       "       [1. , 4.5, 1.7],\n",
       "       [1. , 6.3, 1.8],\n",
       "       [1. , 5.8, 1.8],\n",
       "       [1. , 6.1, 2.5],\n",
       "       [1. , 5.1, 2. ],\n",
       "       [1. , 5.3, 1.9],\n",
       "       [1. , 5.5, 2.1],\n",
       "       [1. , 5. , 2. ],\n",
       "       [1. , 5.1, 2.4],\n",
       "       [1. , 5.3, 2.3],\n",
       "       [1. , 5.5, 1.8],\n",
       "       [1. , 6.7, 2.2],\n",
       "       [1. , 6.9, 2.3],\n",
       "       [1. , 5. , 1.5],\n",
       "       [1. , 5.7, 2.3],\n",
       "       [1. , 4.9, 2. ],\n",
       "       [1. , 6.7, 2. ],\n",
       "       [1. , 4.9, 1.8],\n",
       "       [1. , 5.7, 2.1],\n",
       "       [1. , 6. , 1.8],\n",
       "       [1. , 4.8, 1.8],\n",
       "       [1. , 4.9, 1.8],\n",
       "       [1. , 5.6, 2.1],\n",
       "       [1. , 5.8, 1.6],\n",
       "       [1. , 6.1, 1.9],\n",
       "       [1. , 6.4, 2. ],\n",
       "       [1. , 5.6, 2.2],\n",
       "       [1. , 5.1, 1.5],\n",
       "       [1. , 5.6, 1.4],\n",
       "       [1. , 6.1, 2.3],\n",
       "       [1. , 5.6, 2.4],\n",
       "       [1. , 5.5, 1.8],\n",
       "       [1. , 4.8, 1.8],\n",
       "       [1. , 5.4, 2.1],\n",
       "       [1. , 5.6, 2.4],\n",
       "       [1. , 5.1, 2.3],\n",
       "       [1. , 5.1, 1.9],\n",
       "       [1. , 5.9, 2.3],\n",
       "       [1. , 5.7, 2.5],\n",
       "       [1. , 5.2, 2.3],\n",
       "       [1. , 5. , 1.9],\n",
       "       [1. , 5.2, 2. ],\n",
       "       [1. , 5.4, 2.3],\n",
       "       [1. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
    "X_with_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-train split\n",
    "test_ratio = 0.2\n",
    "val_ratio = 0.2\n",
    "total_size = len(X_with_bias)\n",
    "\n",
    "test_size = int(test_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "train_size = total_size - test_size - val_size\n",
    "\n",
    "rndm_indices = np.random.permutation(total_size)\n",
    "\n",
    "X_train = X_with_bias[rndm_indices[:train_size]]\n",
    "y_train = y[rndm_indices[:train_size]]\n",
    "\n",
    "X_val = X_with_bias[rndm_indices[train_size:-test_size]]\n",
    "y_val = y[rndm_indices[train_size:-test_size]]\n",
    "\n",
    "X_test = X_with_bias[rndm_indices[-test_size:]]\n",
    "y_test = y[rndm_indices[-test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    n_classes = y.max() + 1\n",
    "    m = len(y)\n",
    "    y_one_hot = np.zeros((m, n_classes))\n",
    "    y_one_hot[np.arange(m), y] = 1\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding y sets\n",
    "Y_train = to_one_hot(y_train)\n",
    "Y_val = to_one_hot(y_val)\n",
    "Y_test = to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logs):\n",
    "    exps = np.exp(logs)\n",
    "    exps_sum = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps / exps_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.7576833474329727\n",
      "500 0.651786036657424\n",
      "1000 0.554875221552612\n",
      "1500 0.49655231616473067\n",
      "2000 0.4572577697698041\n",
      "2500 0.42846979374397876\n",
      "3000 0.4060872607248388\n",
      "3500 0.3879298655757583\n",
      "4000 0.3727355165212827\n",
      "4500 0.35972059011556223\n",
      "5000 0.3483698542871998\n"
     ]
    }
   ],
   "source": [
    "#Now to train the model...\n",
    "eta = 0.01\n",
    "n_iterations = 5001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-7\n",
    "\n",
    "Theta = np.random.randn(X_train.shape[1], len(np.unique(y_train)))\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    logits = X_train.dot(Theta)\n",
    "    y_proba = softmax(logits)\n",
    "    \n",
    "    if iteration % 500 == 0:\n",
    "        loss = -np.mean(np.sum(Y_train * np.log(y_proba + epsilon), axis=1))\n",
    "        print(iteration, loss)\n",
    "    \n",
    "    error = y_proba - Y_train\n",
    "    gradient = 1/m * X_train.T.dot(error)\n",
    "    Theta = Theta - gradient * eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_val.dot(Theta)\n",
    "y_predict = np.argmax(softmax(logits), axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_val)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
